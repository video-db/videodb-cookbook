{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9e89948",
      "metadata": {
        "id": "f9e89948"
      },
      "source": [
        "# Clip as the Main Control Layer in VideoDB Editor\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/editor/feature/clip_control_layer.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is a comprehensive walkthrough of the **Clip object** in VideoDB Editor.\n",
        "\n",
        "The Clip is the **most important object** in Editor. While **Assets** define *what* content you're using (video, image, audio), and **Tracks** define *layering*, the **Clip** is where you control **how** that content appears and behaves on screen.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How Clip parameters control position, size, and transparency\n",
        "- Using `fit` to handle different aspect ratios\n",
        "- Applying visual filters for style and mood\n",
        "- Adding transitions for smooth entry/exit effects\n",
        "- Combining Clips to create picture-in-picture, split-screen, and sequential compositions\n",
        "\n",
        "By the end of this notebook, you'll understand why the Clip is the **central control layer** for video composition in Editor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bb78a53",
      "metadata": {
        "id": "8bb78a53"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 1: Install dependencies\n",
        "\n",
        "Lets install VideoDB SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "93d0dfc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93d0dfc5",
        "outputId": "aa8fa64b-66c8-4e8d-f7d9-7dd69a83d7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for videodb (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip -q install git+https://github.com/video-db/videodb-python.git@ankit/add-videodb-editor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0093b276",
      "metadata": {
        "id": "0093b276"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 2: Connect to VideoDB\n",
        "\n",
        "Run the next cell and enter your `VIDEO_DB_API_KEY` when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e67cb440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67cb440",
        "outputId": "13172482-50c4-4ffc-a9df-d721b777997c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your VideoDB API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Connected to VideoDB securely!\n"
          ]
        }
      ],
      "source": [
        "import videodb\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Please enter your VideoDB API Key: \")\n",
        "\n",
        "os.environ[\"VIDEO_DB_API_KEY\"] = api_key\n",
        "\n",
        "conn = videodb.connect()\n",
        "\n",
        "print(\"Connected to VideoDB securely!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2c9fdc",
      "metadata": {
        "id": "fc2c9fdc"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 3: Connect to a collection\n",
        "\n",
        "A **collection** is where your uploaded assets live (videos, images, audio).\n",
        "We'll upload video assets next and use their `id` values inside Editor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c059b50",
      "metadata": {
        "id": "5c059b50"
      },
      "outputs": [],
      "source": [
        "coll = conn.get_collection()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fdcf633",
      "metadata": {
        "id": "9fdcf633"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 4: Upload video assets\n",
        "\n",
        "Editor works with **assets stored in VideoDB**.\n",
        "\n",
        "For this notebook, we'll upload **three different videos**:\n",
        "- **video1**: Used for all single-clip demonstrations (position, scale, filters, etc.)\n",
        "- **video2**: Used in multi-clip compositions alongside video1\n",
        "- **video3**: Used in sequential clip demonstrations\n",
        "\n",
        "This approach makes multi-clip examples visually clear (you'll see different content, not the same video repeated).\n",
        "\n",
        "> Tip: When you re-run this notebook, you can skip re-uploading and fetch existing assets by ID instead (see the commented snippet below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "61a5a7d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61a5a7d5",
        "outputId": "0a6ef7ea-3f7a-4059-c65f-bcbbf7710e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded video1: m-z-01944c5f-3fa4-7782-8143-ccfc9b46b10b\n",
            "Uploaded video2: m-z-019b49b9-8618-7510-9cc7-6e0133c88bf1\n",
            "Uploaded video3: m-z-019b446a-ba0f-7891-8533-dd75f72ea251\n"
          ]
        }
      ],
      "source": [
        "# Upload three different video assets\n",
        "video1 = coll.upload(url=\"https://www.youtube.com/watch?v=k2kiyWu_XNc\")\n",
        "print(\"Uploaded video1:\", video1.id)\n",
        "\n",
        "video2 = coll.upload(url=\"https://www.youtube.com/watch?v=RB9nyUyNI2s\")\n",
        "print(\"Uploaded video2:\", video2.id)\n",
        "\n",
        "video3 = coll.upload(url=\"https://www.youtube.com/watch?v=ExJZAegsOis\")\n",
        "print(\"Uploaded video3:\", video3.id)\n",
        "\n",
        "# Optional re-run pattern (don't upload again):\n",
        "# video1 = coll.get_video(\"vid_id\")\n",
        "# video2 = coll.get_video(\"vid_id\")\n",
        "# video3 = coll.get_video(\"vid_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8edb920",
      "metadata": {
        "id": "b8edb920"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 5: Import Editor building blocks\n",
        "\n",
        "We'll use the core Editor objects throughout this notebook:\n",
        "- `Timeline`: the global canvas (resolution + background)\n",
        "- `Track`: a layer on the timeline\n",
        "- `Clip`: the container that controls how assets appear\n",
        "- `VideoAsset`: references your uploaded video by `id`\n",
        "- `Position`, `Offset`, `Filter`, `Transition`: Clip effect parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8d5cd25f",
      "metadata": {
        "id": "8d5cd25f"
      },
      "outputs": [],
      "source": [
        "from videodb import play_stream\n",
        "from videodb.editor import Timeline, Track, Clip, VideoAsset, Position, Offset, Filter, Transition, Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f76c3a7",
      "metadata": {
        "id": "0f76c3a7"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: Your First Clip\n",
        "\n",
        "## ðŸ“¦ Step 6: Create a basic Clip\n",
        "\n",
        "Let's start with the simplest possible example: one video clip with default settings.\n",
        "\n",
        "This demonstrates the **minimum required structure** for any Editor composition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f406f62c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f406f62c",
        "outputId": "e8af5819-fac1-4a57-eca2-3e64b2cff4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/95ccf01d-925c-4a34-aea4-491ff0275bd9.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/95ccf01d-925c-4a34-aea4-491ff0275bd9.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e711c70>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Create a simple clip\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10\n",
        ")\n",
        "\n",
        "# Add to track and timeline\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "# Generate and play\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d6db52",
      "metadata": {
        "id": "25d6db52"
      },
      "source": [
        "**What just happened?**\n",
        "\n",
        "We created a 10-second video clip with default settings:\n",
        "- No position specified (defaults to filling the screen)\n",
        "- No effects\n",
        "- No transitions\n",
        "- Just the raw video playing for 10 seconds\n",
        "\n",
        "Now let's see how Clip parameters give us control."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a8e77e",
      "metadata": {
        "id": "b4a8e77e"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: Position Control\n",
        "\n",
        "## ðŸ“¦ Step 7: Position â€” The 9 Zones\n",
        "\n",
        "The `position` parameter places your clip in one of **9 preset zones** on the screen:\n",
        "\n",
        "```\n",
        "top_left      top       top_right\n",
        "left          center    right\n",
        "bottom_left   bottom    bottom_right\n",
        "```\n",
        "\n",
        "Let's position the same video in the **top-right corner**. We'll also set `fit=None` so the video keeps its original size rather than filling the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9f86390",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b9f86390",
        "outputId": "5826073c-466b-4000-89c6-2946ebfc06e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/782fe77a-6b5f-420c-a7bd-e3ca590521a4.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/782fe77a-6b5f-420c-a7bd-e3ca590521a4.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3f2cb500>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_right,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ba10f9",
      "metadata": {
        "id": "e1ba10f9"
      },
      "source": [
        "**Notice**: The video is now anchored to the top-right corner of the screen.\n",
        "\n",
        "**Available positions**: `Position.top`, `Position.topRight`, `Position.right`, `Position.bottomRight`, `Position.bottom`, `Position.bottomLeft`, `Position.left`, `Position.topLeft`, `Position.center`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c376630d",
      "metadata": {
        "id": "c376630d"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 8: Offset â€” Fine-Tuning Position\n",
        "\n",
        "Sometimes the 9 preset zones aren't enough. The `offset` parameter lets you **fine-tune** the position.\n",
        "\n",
        "Offset values are **relative to viewport dimensions**:\n",
        "- `x=0.1` moves the clip **10% to the right**\n",
        "- `x=-0.1` moves it **10% to the left**\n",
        "- `y=0.1` moves it **10% down**\n",
        "- `y=-0.1` moves it **10% up**\n",
        "\n",
        "Let's position a clip in the center, then shift it slightly to the right and down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f274c295",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f274c295",
        "outputId": "b2c98794-7e00-4762-98e6-c6f9c7d267d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/d674150d-a442-49fb-b753-0347f1bd777a.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/d674150d-a442-49fb-b753-0347f1bd777a.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e4b78c0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    offset=Offset(x=0.15, y=0.1),\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab31652f",
      "metadata": {
        "id": "ab31652f"
      },
      "source": [
        "**Key insight**: `position` gives you **macro placement** (9 zones), while `offset` gives you **micro adjustment** for precise control."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ec37c1",
      "metadata": {
        "id": "28ec37c1"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: Size and Transparency\n",
        "\n",
        "## ðŸ“¦ Step 9: Scale â€” Making Things Bigger or Smaller\n",
        "\n",
        "The `scale` parameter is a **size multiplier**:\n",
        "- `scale=1.0` â€” Original size (default)\n",
        "- `scale=0.5` â€” Half size\n",
        "- `scale=2.0` â€” Double size\n",
        "\n",
        "Range: 0.0 to 10.0\n",
        "\n",
        "Let's create a small video in the corner â€” think \"picture-in-picture\" style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a9ece83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "9a9ece83",
        "outputId": "cba203d9-f93e-4ef8-b6e2-a15c7cba1a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/8b7e198a-88ed-444b-949a-6326375c5944.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/8b7e198a-88ed-444b-949a-6326375c5944.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3f13f6e0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.5,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780dcb00",
      "metadata": {
        "id": "780dcb00"
      },
      "source": [
        "**Result**: The video is now **50% of its original size**, positioned in the top-left corner.\n",
        "\n",
        "This is the foundation of picture-in-picture effects!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bfd4c1",
      "metadata": {
        "id": "f1bfd4c1"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 10: Opacity â€” Controlling Transparency\n",
        "\n",
        "The `opacity` parameter controls how **transparent** the clip is:\n",
        "- `opacity=1.0` â€” Fully opaque (default)\n",
        "- `opacity=0.5` â€” 50% transparent\n",
        "- `opacity=0.0` â€” Fully invisible\n",
        "\n",
        "Range: 0.0 to 1.0\n",
        "\n",
        "Let's create a semi-transparent video overlay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7fe8806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f7fe8806",
        "outputId": "b639ae72-f1b4-4b06-de4f-f6db0cf5582c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/07860757-39ee-465c-ad94-b23b6db6479e.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/07860757-39ee-465c-ad94-b23b6db6479e.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e511eb0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    opacity=0.3,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58c9a2c9",
      "metadata": {
        "id": "58c9a2c9"
      },
      "source": [
        "**Notice**: The video is now **30% opaque** (70% transparent), allowing the background to show through.\n",
        "\n",
        "Opacity is essential for watermarks, overlays, and layered compositions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2a0a0",
      "metadata": {
        "id": "dba2a0a0"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 11: Combining Scale and Opacity\n",
        "\n",
        "Clip parameters work together. Let's create a large, semi-transparent video centered on screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c70b95b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "c70b95b3",
        "outputId": "41b7c965-f3be-43c5-aefe-9a081a5b3641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/998a06d1-2422-421e-88bc-baed8fff2217.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/998a06d1-2422-421e-88bc-baed8fff2217.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e512a20>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    scale=1.5,\n",
        "    opacity=0.3,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2da43b5",
      "metadata": {
        "id": "a2da43b5"
      },
      "source": [
        "**Result**: The video is **1.5Ã— larger** than normal and **30% opaque**.\n",
        "\n",
        "This demonstrates how Clip parameters compose naturally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e3d4f0",
      "metadata": {
        "id": "84e3d4f0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: Fit Modes\n",
        "\n",
        "## ðŸ“¦ Step 12: Understanding Fit\n",
        "\n",
        "When your video's aspect ratio doesn't match the timeline resolution, `fit` determines the scaling behavior.\n",
        "\n",
        "**Four fit modes**:\n",
        "\n",
        "1. **`Fit.crop`** (default) â€” Scales to fill the viewport, crops edges if needed\n",
        "2. **`Fit.contain`** â€” Scales to show entire video, may add letterboxing\n",
        "3. **`Fit.cover`** â€” Stretches to fill viewport, ignoring aspect ratio (may distort)\n",
        "4. **`Fit.none`** â€” Original dimensions, no scaling\n",
        "\n",
        "Let's see `Fit.crop` in action with a portrait-oriented timeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70b7f3ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "70b7f3ff",
        "outputId": "3ca27ddd-b18c-4528-a0ae-2ce3f53751e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/9cc77110-5f90-4994-8882-61423f0c8e16.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/9cc77110-5f90-4994-8882-61423f0c8e16.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e631eb0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "timeline.resolution = \"600x1068\"  # Portrait orientation (9:16)\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    fit=Fit.crop\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7682e3a0",
      "metadata": {
        "id": "7682e3a0"
      },
      "source": [
        "**`Fit.crop`**: The video fills the entire viewport. If the aspect ratios don't match, the edges are cropped.\n",
        "\n",
        "Best for: Backgrounds, full-screen content where you want no black bars."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31110ce4",
      "metadata": {
        "id": "31110ce4"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Visual Effects\n",
        "\n",
        "## ðŸ“¦ Step 13: Filters â€” Color Treatments\n",
        "\n",
        "The `filter` parameter applies **color treatments** to your clip:\n",
        "\n",
        "- `Filter.greyscale` â€” Remove color\n",
        "- `Filter.blur` â€” Blur the video\n",
        "- `Filter.contrast` â€” Increase contrast\n",
        "- `Filter.darken` â€” Darken the scene\n",
        "- `Filter.lighten` â€” Lighten the scene\n",
        "- `Filter.muted` â€” Reduce saturation and contrast\n",
        "- `Filter.negative` â€” Invert colors\n",
        "- `Filter.boost` â€” Boost contrast and saturation\n",
        "\n",
        "Let's apply a greyscale filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c1112efb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "c1112efb",
        "outputId": "a008470f-4ef2-42e7-887b-47ca37f56543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/124e48e0-4768-4c57-ad55-971007d770da.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/124e48e0-4768-4c57-ad55-971007d770da.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e512c00>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    filter=Filter.greyscale\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5ecf77",
      "metadata": {
        "id": "af5ecf77"
      },
      "source": [
        "**Result**: The video now plays in black and white.\n",
        "\n",
        "Try experimenting with other filters: `Filter.blur`, `Filter.negative`, `Filter.boost`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c2033c",
      "metadata": {
        "id": "52c2033c"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 14: Combining Filter with Position and Scale\n",
        "\n",
        "Let's create a small, greyscale video in the corner â€” a common pattern for background overlays or secondary content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "52af82a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "52af82a0",
        "outputId": "b9f10ac0-e8b2-4a5f-9633-ec7a81f84293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/ab65694c-7ff4-400c-899c-24aed14e010c.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/ab65694c-7ff4-400c-899c-24aed14e010c.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3de8be90>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.4,\n",
        "    filter=Filter.greyscale,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78713f7",
      "metadata": {
        "id": "c78713f7"
      },
      "source": [
        "**Result**: A small (40% size), black-and-white video in the top-left corner.\n",
        "\n",
        "Notice how naturally Clip parameters combine: position + scale + filter all work together."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb59d322",
      "metadata": {
        "id": "cb59d322"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 6: Transitions\n",
        "\n",
        "## ðŸ“¦ Step 15: Fade In and Fade Out\n",
        "\n",
        "The `transition` parameter controls how a clip **enters** and **exits**.\n",
        "\n",
        "Most commonly, you'll use fade transitions:\n",
        "- `in_=\"fade\"` â€” Fade from transparent to opaque\n",
        "- `out=\"fade\"` â€” Fade from opaque to transparent\n",
        "- `duration=2` â€” Transition duration in seconds\n",
        "\n",
        "**Important**: Note the underscore in `in_=\"fade\"` (because `in` is a Python keyword).\n",
        "\n",
        "Let's create a clip that fades in, plays, then fades out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b2d95ad0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b2d95ad0",
        "outputId": "9e69ea9b-1855-4938-be80-17e127517ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/2916c77f-f10d-4217-92bb-12d454cac92b.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/2916c77f-f10d-4217-92bb-12d454cac92b.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e512f30>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=2)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68adfa33",
      "metadata": {
        "id": "68adfa33"
      },
      "source": [
        "**What you'll see**:\n",
        "- First 2 seconds: Video fades in\n",
        "- Middle 6 seconds: Video plays normally\n",
        "- Last 2 seconds: Video fades out\n",
        "\n",
        "Transitions make your edits feel polished and professional."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d96ff5",
      "metadata": {
        "id": "57d96ff5"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 16: Transition with Delayed Start\n",
        "\n",
        "You can add a clip later on the timeline using `track.add_clip(start=...)`.\n",
        "\n",
        "Let's make the clip appear at the 2-second mark with a fade-in transition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4e118435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "4e118435",
        "outputId": "bc692724-7aba-4f6f-8ec7-281c4653ee15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/d63688cc-4d4f-47d4-98c4-d5e53590dbb6.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/d63688cc-4d4f-47d4-98c4-d5e53590dbb6.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc608aa690>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=8,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1.5)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(2, clip)  # Clip starts at 2 seconds on the timeline\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c143c60b",
      "metadata": {
        "id": "c143c60b"
      },
      "source": [
        "**Timeline structure**:\n",
        "- 0-2 seconds: Blank (gray background)\n",
        "- 2-10 seconds: Video plays with fade in/out\n",
        "\n",
        "This is your first glimpse of **timeline timing** â€” we'll explore this more shortly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac15e41f",
      "metadata": {
        "id": "ac15e41f"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 7: Combining Everything\n",
        "\n",
        "## ðŸ“¦ Step 17: The Full Clip Effect Stack\n",
        "\n",
        "Let's combine multiple Clip parameters to create a stylized effect:\n",
        "- Position in bottom-left\n",
        "- Scale down to 70%\n",
        "- Semi-transparent (30% opacity)\n",
        "- Greyscale filter\n",
        "- Fade in/out transitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fa966130",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "fa966130",
        "outputId": "948cf72f-2359-479e-f9d9-85ac49f23fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/c1f311f4-ae3a-4a2e-9a70-f68c29abeadd.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/c1f311f4-ae3a-4a2e-9a70-f68c29abeadd.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3f81bbc0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.bottom_left,\n",
        "    scale=0.7,\n",
        "    opacity=0.3,\n",
        "    filter=Filter.greyscale,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=3),\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b49490",
      "metadata": {
        "id": "30b49490"
      },
      "source": [
        "**Result**: A small, semi-transparent, black-and-white video in the bottom-right that fades in and out.\n",
        "\n",
        "This demonstrates the **Clip effect stack** â€” all parameters working together to create sophisticated visual effects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecbdb7f0",
      "metadata": {
        "id": "ecbdb7f0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 8: The \"Double Start\" Concept\n",
        "\n",
        "## ðŸ“¦ Step 18: Understanding Two Types of \"Start\"\n",
        "\n",
        "This is a crucial concept that often confuses newcomers. There are **two different \"start\" parameters**:\n",
        "\n",
        "1. **`VideoAsset(start=...)`** â€” **TRIMMING**: Skips the beginning of the source video\n",
        "2. **`track.add_clip(start=...)`** â€” **TIMING**: Delays when the clip appears on the timeline\n",
        "\n",
        "These are independent!\n",
        "\n",
        "Let's demonstrate:\n",
        "- We have a 60-second video\n",
        "- We want to show seconds 10-20 of that video (a 10-second segment)\n",
        "- But we want it to appear at the 5-second mark on our timeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7ee156c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "7ee156c3",
        "outputId": "f4bf9166-7450-4178-eccb-fd38ec7a6ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/fd86a76a-7bf3-4006-91c8-5dc1b418a476.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/fd86a76a-7bf3-4006-91c8-5dc1b418a476.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e5123c0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(\n",
        "        id=video1.id,\n",
        "        start=10  # TRIMMING: Skip first 10 seconds of source video\n",
        "    ),\n",
        "    duration=10  # Play for 10 seconds (showing seconds 10-20 of source)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(5, clip)  # TIMING: Place at 5-second mark on timeline\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0290039",
      "metadata": {
        "id": "a0290039"
      },
      "source": [
        "**Timeline breakdown**:\n",
        "- 0-5 seconds: Blank (gray background)\n",
        "- 5-15 seconds: Video plays (showing seconds 10-20 of the original source)\n",
        "\n",
        "**Key distinction**:\n",
        "- `VideoAsset(start=10)` â€” \"Start reading from the source video at the 10-second mark\"\n",
        "- `track.add_clip(5, clip)` â€” \"Place this clip at the 5-second position on the timeline\"\n",
        "\n",
        "Understanding this \"double start\" concept is essential for precise editing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d58ae52",
      "metadata": {
        "id": "5d58ae52"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 9: Multi-Clip Compositions\n",
        "\n",
        "## ðŸ“¦ Step 19: Picture-in-Picture Effect\n",
        "\n",
        "Now that we understand all Clip parameters, let's create a **picture-in-picture** composition using **two different videos**:\n",
        "- Main video (full screen) â€” video1\n",
        "- Small overlay video (bottom-right corner) â€” video2\n",
        "\n",
        "We'll add both clips to the same track at the same time â€” they'll play simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f23a2a59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f23a2a59",
        "outputId": "453b4ec8-0051-462d-dd93-98118a36ac1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/f8669369-b2b7-4b03-a267-22ee9881e218.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/f8669369-b2b7-4b03-a267-22ee9881e218.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e48bb00>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Main video (full screen) - video1\n",
        "main_clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    fit=Fit.crop\n",
        ")\n",
        "\n",
        "# Small overlay video (bottom-right, greyscale) - video2\n",
        "overlay_clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.7,\n",
        "    filter=Filter.greyscale,\n",
        "    offset=Offset(x=-0.02, y=-0.02),  # Small margin from edge\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, main_clip)\n",
        "track.add_clip(0, overlay_clip)  # Same start time = simultaneous playback\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2306f94",
      "metadata": {
        "id": "c2306f94"
      },
      "source": [
        "**Result**: A classic picture-in-picture layout with **two different videos**!\n",
        "\n",
        "- video1 (main) fills the screen\n",
        "- video2 (overlay, 70% size, greyscale) sits in the top-left corner\n",
        "- Both play simultaneously\n",
        "\n",
        "Notice how `track.add_clip(0, ...)` for both clips makes them play at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0f16a9",
      "metadata": {
        "id": "4a0f16a9"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 20: Split-Screen Effect\n",
        "\n",
        "Let's create a split-screen composition using **two different videos side-by-side**.\n",
        "\n",
        "Strategy:\n",
        "- video1 on the left\n",
        "- video2 on the right (with greyscale filter)\n",
        "- Scale both to 50% width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4a91dd2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "4a91dd2e",
        "outputId": "a9a791a7-326d-4da7-a7a0-5a6f3a5e263b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/a7619042-7c3e-48ca-9554-0980057a43d4.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/a7619042-7c3e-48ca-9554-0980057a43d4.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e5130e0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Left side clip - video1\n",
        "left_clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.left,\n",
        "    scale=1,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "# Right side clip - video2 (with greyscale filter)\n",
        "right_clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.right,\n",
        "    scale=1,\n",
        "    filter=Filter.greyscale,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, left_clip)\n",
        "track.add_clip(0, right_clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da51db3",
      "metadata": {
        "id": "4da51db3"
      },
      "source": [
        "**Result**: A split-screen effect with **two different videos**:\n",
        "- Left side: video1 (color)\n",
        "- Right side: video2 (greyscale)\n",
        "\n",
        "This demonstrates how **Clip controls enable spatial composition** â€” placing multiple clips in precise positions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f735e7d0",
      "metadata": {
        "id": "f735e7d0"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 21: Sequential Clips with Transitions\n",
        "\n",
        "Clips don't have to overlap. Let's create **three different videos playing one after another**, each with fade transitions and different effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b29879c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b29879c2",
        "outputId": "385ed774-f5c8-408e-d37d-b34941fd05e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stream URL: https://play.videodb.io/v1/4ff53418-6603-4a78-a54c-1f742d77faa8.m3u8\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/4ff53418-6603-4a78-a54c-1f742d77faa8.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7cfc3e512cf0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# First clip (0-6 seconds)\n",
        "clip1 = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "# Second clip (6-12 seconds)\n",
        "clip2 = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "# Third clip (12-18 seconds)\n",
        "clip3 = Clip(\n",
        "    asset=VideoAsset(id=video3.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip1)\n",
        "track.add_clip(6, clip2)\n",
        "track.add_clip(12, clip3)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc0c38c",
      "metadata": {
        "id": "1fc0c38c"
      },
      "source": [
        "**ðŸŽ¬ Result**: A continuous 18-second video with smooth transitions between three different scenes, each with its own unique styling (first clip normal, second clip greyscale, third clip scaled down)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9229622c",
      "metadata": {
        "id": "9229622c"
      },
      "source": [
        "**Timeline structure**:\n",
        "- 0-6s: Normal video with fade in/out\n",
        "- 6-12s: Greyscale video with fade in/out\n",
        "- 12-18s: Smaller video (70% size) with fade in/out\n",
        "\n",
        "Each clip has different visual properties, demonstrating how **Clip acts as the control layer** for every piece of content on your timeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e184baa8",
      "metadata": {
        "id": "e184baa8"
      },
      "source": [
        "---\n",
        "\n",
        "# Wrap-Up\n",
        "\n",
        "## What You've Learned\n",
        "\n",
        "Congratulations! You now understand the **Clip** object â€” the most important control layer in VideoDB Editor.\n",
        "\n",
        "**Key concepts covered**:\n",
        "\n",
        "1. **Asset vs Clip**: Assets provide content; Clips control presentation\n",
        "2. **Position**: 9 preset zones (`Position.center`, `Position.topRight`, etc.)\n",
        "3. **Offset**: Fine-tuning position with relative x/y values\n",
        "4. **Scale**: Size multiplier (0.0 to 10.0)\n",
        "5. **Opacity**: Transparency control (0.0 to 1.0)\n",
        "6. **Fit modes**: How assets scale to viewport (`crop`, `contain`, `cover`, `none`)\n",
        "7. **Filters**: Color treatments (`greyscale`, `blur`, `contrast`, etc.)\n",
        "8. **Transitions**: Fade in/out effects\n",
        "9. **Double Start**: `VideoAsset(start=...)` vs `track.add_clip(start=...)`\n",
        "10. **Composition**: Combining multiple clips with different effects\n",
        "\n",
        "\n",
        "---\n",
        "Every parameter works together to give you complete control over how content appears.\n",
        "\n",
        "## Experiment Further\n",
        "\n",
        "Try these ideas to deepen your understanding:\n",
        "\n",
        "1. **Create a 4-way split**: Position four clips in each corner\n",
        "2. **Animate with opacity**: Create clips with varying opacity levels\n",
        "3. **Filter experiments**: Try all filter types to see their effects\n",
        "4. **Complex timing**: Use `VideoAsset(start=...)` and `track.add_clip(start=...)` together\n",
        "5. **Layer effects**: Combine multiple filters, scales, and positions\n",
        "\n",
        "The Clip object is your primary tool for video composition in Editor â€” master it, and you can build any visual effect you imagine!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
