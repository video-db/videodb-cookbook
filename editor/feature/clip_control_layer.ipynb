{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f9e89948",
      "metadata": {
        "id": "f9e89948"
      },
      "source": [
        "# Clip as the Main Control Layer in VideoDB Editor\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/editor/feature/clip_control_layer.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is a comprehensive walkthrough of the **Clip object** in VideoDB Editor.\n",
        "\n",
        "The Clip is the **most important object** in Editor. While **Assets** define *what* content you're using (video, image, audio), and **Tracks** define *layering*, the **Clip** is where you control **how** that content appears and behaves on screen.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How Clip parameters control position, size, and transparency\n",
        "- Using `fit` to handle different aspect ratios\n",
        "- Applying visual filters for style and mood\n",
        "- Adding transitions for smooth entry/exit effects\n",
        "- Combining Clips to create picture-in-picture, split-screen, and sequential compositions\n",
        "\n",
        "By the end of this notebook, you'll understand why the Clip is the **central control layer** for video composition in Editor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bb78a53",
      "metadata": {
        "id": "8bb78a53"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 1: Install dependencies\n",
        "\n",
        "Lets install VideoDB SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "93d0dfc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93d0dfc5",
        "outputId": "4e7c65ed-2726-4dab-cef3-daf3844cff08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for videodb (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip -q install videodb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0093b276",
      "metadata": {
        "id": "0093b276"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 2: Connect to VideoDB\n",
        "\n",
        "Run the next cell and enter your `VIDEO_DB_API_KEY` when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e67cb440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67cb440",
        "outputId": "35f98933-29d9-48ff-bad5-9cbb374b8ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your VideoDB API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Connected to VideoDB securely!\n"
          ]
        }
      ],
      "source": [
        "import videodb\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Please enter your VideoDB API Key: \")\n",
        "\n",
        "os.environ[\"VIDEO_DB_API_KEY\"] = api_key\n",
        "\n",
        "conn = videodb.connect()\n",
        "\n",
        "print(\"Connected to VideoDB securely!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc2c9fdc",
      "metadata": {
        "id": "fc2c9fdc"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 3: Connect to a collection\n",
        "\n",
        "A **collection** is where your uploaded assets live (videos, images, audio).\n",
        "We'll upload video assets next and use their `id` values inside Editor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c059b50",
      "metadata": {
        "id": "5c059b50"
      },
      "outputs": [],
      "source": [
        "coll = conn.get_collection()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fdcf633",
      "metadata": {
        "id": "9fdcf633"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 4: Upload video assets\n",
        "\n",
        "Editor works with **assets stored in VideoDB**.\n",
        "\n",
        "For this notebook, we'll upload **three different videos**:\n",
        "- **video1**: Used for all single-clip demonstrations (position, scale, filters, etc.)\n",
        "- **video2**: Used in multi-clip compositions alongside video1\n",
        "- **video3**: Used in sequential clip demonstrations\n",
        "\n",
        "This approach makes multi-clip examples visually clear (you'll see different content, not the same video repeated).\n",
        "\n",
        "> Tip: When you re-run this notebook, you can skip re-uploading and fetch existing assets by ID instead (see the commented snippet below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "61a5a7d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61a5a7d5",
        "outputId": "fd93c8d0-96d4-48e3-c1bb-615184e5b6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded video1: m-z-019b6e0e-d801-7763-9931-e914b7f35ba1\n",
            "Uploaded video2: m-z-019b49b9-8618-7510-9cc7-6e0133c88bf1\n",
            "Uploaded video3: m-z-019b446a-ba0f-7891-8533-dd75f72ea251\n"
          ]
        }
      ],
      "source": [
        "# Upload three different video assets\n",
        "video1 = coll.upload(url=\"https://www.youtube.com/watch?v=HAX2RuZm-Fk\")\n",
        "print(\"Uploaded video1:\", video1.id)\n",
        "\n",
        "video2 = coll.upload(url=\"https://www.youtube.com/watch?v=RB9nyUyNI2s\")\n",
        "print(\"Uploaded video2:\", video2.id)\n",
        "\n",
        "video3 = coll.upload(url=\"https://www.youtube.com/watch?v=ExJZAegsOis\")\n",
        "print(\"Uploaded video3:\", video3.id)\n",
        "\n",
        "# Optional re-run pattern (don't upload again):\n",
        "# video1 = coll.get_video(\"vid_id\")\n",
        "# video2 = coll.get_video(\"vid_id\")\n",
        "# video3 = coll.get_video(\"vid_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8edb920",
      "metadata": {
        "id": "b8edb920"
      },
      "source": [
        "---\n",
        "## ðŸ“¦ Step 5: Import Editor building blocks\n",
        "\n",
        "We'll use the core Editor objects throughout this notebook:\n",
        "- `Timeline`: the global canvas (resolution + background)\n",
        "- `Track`: a layer on the timeline\n",
        "- `Clip`: the container that controls how assets appear\n",
        "- `VideoAsset`: references your uploaded video by `id`\n",
        "- `Position`, `Offset`, `Filter`, `Transition`: Clip effect parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8d5cd25f",
      "metadata": {
        "id": "8d5cd25f"
      },
      "outputs": [],
      "source": [
        "from videodb import play_stream\n",
        "from videodb.editor import Timeline, Track, Clip, VideoAsset, Position, Offset, Filter, Transition, Fit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f76c3a7",
      "metadata": {
        "id": "0f76c3a7"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: Your First Clip\n",
        "\n",
        "## ðŸ“¦ Step 6: Create a basic Clip\n",
        "\n",
        "Let's start with the simplest possible example: one video clip with default settings.\n",
        "\n",
        "This demonstrates the **minimum required structure** for any Editor composition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f406f62c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f406f62c",
        "outputId": "b752a83d-450d-487e-f39a-c31735d0f333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/06e4bb12-0eac-41cb-abab-6d7111b2a210.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef735a0e900>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/06e4bb12-0eac-41cb-abab-6d7111b2a210.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Create a simple clip\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10\n",
        ")\n",
        "\n",
        "# Add to track and timeline\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "# Generate and play\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d6db52",
      "metadata": {
        "id": "25d6db52"
      },
      "source": [
        "**What just happened?**\n",
        "\n",
        "We created a 10-second video clip with default settings:\n",
        "- No position specified (defaults to filling the screen)\n",
        "- No effects\n",
        "- No transitions\n",
        "- Just the raw video playing for 10 seconds\n",
        "\n",
        "Now let's see how Clip parameters give us control."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4a8e77e",
      "metadata": {
        "id": "b4a8e77e"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: Position Control\n",
        "\n",
        "## ðŸ“¦ Step 7: Position â€” The 9 Zones\n",
        "\n",
        "The `position` parameter places your clip in one of **9 preset zones** on the screen:\n",
        "\n",
        "```\n",
        "top_left      top       top_right\n",
        "left          center    right\n",
        "bottom_left   bottom    bottom_right\n",
        "```\n",
        "\n",
        "Let's position the same video in the **top-right corner**. We'll also set `fit=None` so the video keeps its original size rather than filling the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9f86390",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b9f86390",
        "outputId": "fa934827-3634-4656-8bda-4f66faa40552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/e9d5dbf5-b635-4cd6-b1f2-99f5defe6d60.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef74fbed0d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/e9d5dbf5-b635-4cd6-b1f2-99f5defe6d60.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_right,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ba10f9",
      "metadata": {
        "id": "e1ba10f9"
      },
      "source": [
        "**Notice**: The video is now anchored to the top-right corner of the screen.\n",
        "\n",
        "**Available positions**: `Position.top`, `Position.topRight`, `Position.right`, `Position.bottomRight`, `Position.bottom`, `Position.bottomLeft`, `Position.left`, `Position.topLeft`, `Position.center`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c376630d",
      "metadata": {
        "id": "c376630d"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 8: Offset â€” Fine-Tuning Position\n",
        "\n",
        "Sometimes the 9 preset zones aren't enough. The `offset` parameter lets you **fine-tune** the position.\n",
        "\n",
        "Offset values are **relative to viewport dimensions**:\n",
        "- `x=0.1` moves the clip **10% to the right**\n",
        "- `x=-0.1` moves it **10% to the left**\n",
        "- `y=0.1` moves it **10% down**\n",
        "- `y=-0.1` moves it **10% up**\n",
        "\n",
        "Let's position a clip in the center, then shift it slightly to the right and down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f274c295",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f274c295",
        "outputId": "97859616-c916-42e0-a79c-f7676b347246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/2d752400-2b61-4d5a-851b-3b30759f58b7.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7365184a0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/2d752400-2b61-4d5a-851b-3b30759f58b7.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    offset=Offset(x=0.15, y=0.1),\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab31652f",
      "metadata": {
        "id": "ab31652f"
      },
      "source": [
        "**Key insight**: `position` gives you **macro placement** (9 zones), while `offset` gives you **micro adjustment** for precise control."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ec37c1",
      "metadata": {
        "id": "28ec37c1"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: Size and Transparency\n",
        "\n",
        "## ðŸ“¦ Step 9: Scale â€” Making Things Bigger or Smaller\n",
        "\n",
        "The `scale` parameter is a **size multiplier**:\n",
        "- `scale=1.0` â€” Original size (default)\n",
        "- `scale=0.5` â€” Half size\n",
        "- `scale=2.0` â€” Double size\n",
        "\n",
        "Range: 0.0 to 10.0\n",
        "\n",
        "Let's create a small video in the corner â€” think \"picture-in-picture\" style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a9ece83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "9a9ece83",
        "outputId": "86093616-c05d-4b65-dae8-86a1d8e300f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/62ec501f-b21f-4780-b4de-4dce8e2bacf1.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589a9f0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/62ec501f-b21f-4780-b4de-4dce8e2bacf1.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.5,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780dcb00",
      "metadata": {
        "id": "780dcb00"
      },
      "source": [
        "**Result**: The video is now **50% of its original size**, positioned in the top-left corner.\n",
        "\n",
        "This is the foundation of picture-in-picture effects!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bfd4c1",
      "metadata": {
        "id": "f1bfd4c1"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 10: Opacity â€” Controlling Transparency\n",
        "\n",
        "The `opacity` parameter controls how **transparent** the clip is:\n",
        "- `opacity=1.0` â€” Fully opaque (default)\n",
        "- `opacity=0.5` â€” 50% transparent\n",
        "- `opacity=0.0` â€” Fully invisible\n",
        "\n",
        "Range: 0.0 to 1.0\n",
        "\n",
        "Let's create a semi-transparent video overlay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7fe8806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f7fe8806",
        "outputId": "2a19ed43-8cac-4533-8f6a-e9deb6243474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/e25b9c92-af09-44d2-833d-c6509b89ecee.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589b5f0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/e25b9c92-af09-44d2-833d-c6509b89ecee.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    opacity=0.3,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58c9a2c9",
      "metadata": {
        "id": "58c9a2c9"
      },
      "source": [
        "**Notice**: The video is now **30% opaque** (70% transparent), allowing the background to show through.\n",
        "\n",
        "Opacity is essential for watermarks, overlays, and layered compositions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba2a0a0",
      "metadata": {
        "id": "dba2a0a0"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 11: Combining Scale and Opacity\n",
        "\n",
        "Clip parameters work together. Let's create a large, semi-transparent video centered on screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c70b95b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "c70b95b3",
        "outputId": "f08704c0-de0f-4f93-a891-15091af3a9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/f27ca86c-0b1f-415f-83df-10badc88c117.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589a210>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/f27ca86c-0b1f-415f-83df-10badc88c117.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.center,\n",
        "    scale=1.5,\n",
        "    opacity=0.3,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2da43b5",
      "metadata": {
        "id": "a2da43b5"
      },
      "source": [
        "**Result**: The video is **1.5Ã— larger** than normal and **30% opaque**.\n",
        "\n",
        "This demonstrates how Clip parameters compose naturally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e3d4f0",
      "metadata": {
        "id": "84e3d4f0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: Fit Modes\n",
        "\n",
        "## ðŸ“¦ Step 12: Understanding Fit\n",
        "\n",
        "When your video's aspect ratio doesn't match the timeline resolution, `fit` determines the scaling behavior.\n",
        "\n",
        "**Four fit modes**:\n",
        "\n",
        "1. **`Fit.crop`** (default) â€” Scales to fill the viewport, crops edges if needed\n",
        "2. **`Fit.contain`** â€” Scales to show entire video, may add letterboxing\n",
        "3. **`Fit.cover`** â€” Stretches to fill viewport, ignoring aspect ratio (may distort)\n",
        "4. **`Fit.none`** â€” Original dimensions, no scaling\n",
        "\n",
        "Let's see `Fit.crop` in action with a portrait-oriented timeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70b7f3ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "70b7f3ff",
        "outputId": "fcf02f82-4337-494d-b099-22fbbee800cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/9365055b-0e96-4ac4-9a17-a7921f62334c.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589a300>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/9365055b-0e96-4ac4-9a17-a7921f62334c.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "timeline.resolution = \"600x1068\"  # Portrait orientation (9:16)\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    fit=Fit.crop\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7682e3a0",
      "metadata": {
        "id": "7682e3a0"
      },
      "source": [
        "**`Fit.crop`**: The video fills the entire viewport. If the aspect ratios don't match, the edges are cropped.\n",
        "\n",
        "Best for: Backgrounds, full-screen content where you want no black bars."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31110ce4",
      "metadata": {
        "id": "31110ce4"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Visual Effects\n",
        "\n",
        "## ðŸ“¦ Step 13: Filters â€” Color Treatments\n",
        "\n",
        "The `filter` parameter applies **color treatments** to your clip:\n",
        "\n",
        "- `Filter.greyscale` â€” Remove color\n",
        "- `Filter.blur` â€” Blur the video\n",
        "- `Filter.contrast` â€” Increase contrast\n",
        "- `Filter.darken` â€” Darken the scene\n",
        "- `Filter.lighten` â€” Lighten the scene\n",
        "- `Filter.muted` â€” Reduce saturation and contrast\n",
        "- `Filter.negative` â€” Invert colors\n",
        "- `Filter.boost` â€” Boost contrast and saturation\n",
        "\n",
        "Let's apply a greyscale filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c1112efb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "c1112efb",
        "outputId": "14b9749c-549b-4b23-d6bc-199b0cd1bf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/10834889-7e74-43d3-a608-b633a8c5b729.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589b260>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/10834889-7e74-43d3-a608-b633a8c5b729.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    filter=Filter.greyscale\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5ecf77",
      "metadata": {
        "id": "af5ecf77"
      },
      "source": [
        "**Result**: The video now plays in black and white.\n",
        "\n",
        "Try experimenting with other filters: `Filter.blur`, `Filter.negative`, `Filter.boost`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c2033c",
      "metadata": {
        "id": "52c2033c"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 14: Combining Filter with Position and Scale\n",
        "\n",
        "Let's create a small, greyscale video in the corner â€” a common pattern for background overlays or secondary content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "52af82a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "52af82a0",
        "outputId": "76886a7c-e85f-4e9b-ce6b-6c9b52495104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/a1ff905e-ca2e-4f05-9d21-a551a4333070.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589aed0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/a1ff905e-ca2e-4f05-9d21-a551a4333070.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.4,\n",
        "    filter=Filter.greyscale,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78713f7",
      "metadata": {
        "id": "c78713f7"
      },
      "source": [
        "**Result**: A small (40% size), black-and-white video in the top-left corner.\n",
        "\n",
        "Notice how naturally Clip parameters combine: position + scale + filter all work together."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb59d322",
      "metadata": {
        "id": "cb59d322"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 6: Transitions\n",
        "\n",
        "## ðŸ“¦ Step 15: Fade In and Fade Out\n",
        "\n",
        "The `transition` parameter controls how a clip **enters** and **exits**.\n",
        "\n",
        "Most commonly, you'll use fade transitions:\n",
        "- `in_=\"fade\"` â€” Fade from transparent to opaque\n",
        "- `out=\"fade\"` â€” Fade from opaque to transparent\n",
        "- `duration=2` â€” Transition duration in seconds\n",
        "\n",
        "**Important**: Note the underscore in `in_=\"fade\"` (because `in` is a Python keyword).\n",
        "\n",
        "Let's create a clip that fades in, plays, then fades out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b2d95ad0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b2d95ad0",
        "outputId": "29defceb-93ea-4ccc-dcd9-96dac43f42d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/acb06e75-6a52-408a-8614-c2742162188f.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7358f7da0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/acb06e75-6a52-408a-8614-c2742162188f.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=2)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68adfa33",
      "metadata": {
        "id": "68adfa33"
      },
      "source": [
        "**What you'll see**:\n",
        "- First 2 seconds: Video fades in\n",
        "- Middle 6 seconds: Video plays normally\n",
        "- Last 2 seconds: Video fades out\n",
        "\n",
        "Transitions make your edits feel polished and professional."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d96ff5",
      "metadata": {
        "id": "57d96ff5"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 16: Transition with Delayed Start\n",
        "\n",
        "You can add a clip later on the timeline using `track.add_clip(start=...)`.\n",
        "\n",
        "Let's make the clip appear at the 2-second mark with a fade-in transition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4e118435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "4e118435",
        "outputId": "e6a5505d-0a35-44fd-de7c-63d3a4d5bde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/61c5b163-d27f-4faa-80c4-e825c7c66c98.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7358c1b20>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/61c5b163-d27f-4faa-80c4-e825c7c66c98.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=8,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1.5)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(2, clip)  # Clip starts at 2 seconds on the timeline\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c143c60b",
      "metadata": {
        "id": "c143c60b"
      },
      "source": [
        "**Timeline structure**:\n",
        "- 0-2 seconds: Blank (gray background)\n",
        "- 2-10 seconds: Video plays with fade in/out\n",
        "\n",
        "This is your first glimpse of **timeline timing** â€” we'll explore this more shortly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac15e41f",
      "metadata": {
        "id": "ac15e41f"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 7: Combining Everything\n",
        "\n",
        "## ðŸ“¦ Step 17: The Full Clip Effect Stack\n",
        "\n",
        "Let's combine multiple Clip parameters to create a stylized effect:\n",
        "- Position in bottom-left\n",
        "- Scale down to 70%\n",
        "- Semi-transparent (30% opacity)\n",
        "- Greyscale filter\n",
        "- Fade in/out transitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fa966130",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "fa966130",
        "outputId": "d24833e2-aeb7-4322-e9d7-74d0d64e3b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/93baf113-3cf9-4968-a575-aa6e5aba1e2e.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7358c2d50>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/93baf113-3cf9-4968-a575-aa6e5aba1e2e.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.bottom_left,\n",
        "    scale=0.7,\n",
        "    opacity=0.3,\n",
        "    filter=Filter.greyscale,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=3),\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30b49490",
      "metadata": {
        "id": "30b49490"
      },
      "source": [
        "**Result**: A small, semi-transparent, black-and-white video in the bottom-right that fades in and out.\n",
        "\n",
        "This demonstrates the **Clip effect stack** â€” all parameters working together to create sophisticated visual effects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecbdb7f0",
      "metadata": {
        "id": "ecbdb7f0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 8: The \"Double Start\" Concept\n",
        "\n",
        "## ðŸ“¦ Step 18: Understanding Two Types of \"Start\"\n",
        "\n",
        "This is a crucial concept that often confuses newcomers. There are **two different \"start\" parameters**:\n",
        "\n",
        "1. **`VideoAsset(start=...)`** â€” **TRIMMING**: Skips the beginning of the source video\n",
        "2. **`track.add_clip(start=...)`** â€” **TIMING**: Delays when the clip appears on the timeline\n",
        "\n",
        "These are independent!\n",
        "\n",
        "Let's demonstrate:\n",
        "- We have a 60-second video\n",
        "- We want to show seconds 10-20 of that video (a 10-second segment)\n",
        "- But we want it to appear at the 5-second mark on our timeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7ee156c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "7ee156c3",
        "outputId": "75c66beb-fcf8-4639-d674-3e432a26b58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/2df78303-f783-4282-b53e-c56186ae89a3.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589a3f0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/2df78303-f783-4282-b53e-c56186ae89a3.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "clip = Clip(\n",
        "    asset=VideoAsset(\n",
        "        id=video1.id,\n",
        "        start=10  # TRIMMING: Skip first 10 seconds of source video\n",
        "    ),\n",
        "    duration=10  # Play for 10 seconds (showing seconds 10-20 of source)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(5, clip)  # TIMING: Place at 5-second mark on timeline\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0290039",
      "metadata": {
        "id": "a0290039"
      },
      "source": [
        "**Timeline breakdown**:\n",
        "- 0-5 seconds: Blank (gray background)\n",
        "- 5-15 seconds: Video plays (showing seconds 10-20 of the original source)\n",
        "\n",
        "**Key distinction**:\n",
        "- `VideoAsset(start=10)` â€” \"Start reading from the source video at the 10-second mark\"\n",
        "- `track.add_clip(5, clip)` â€” \"Place this clip at the 5-second position on the timeline\"\n",
        "\n",
        "Understanding this \"double start\" concept is essential for precise editing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d58ae52",
      "metadata": {
        "id": "5d58ae52"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 9: Multi-Clip Compositions\n",
        "\n",
        "## ðŸ“¦ Step 19: Picture-in-Picture Effect\n",
        "\n",
        "Now that we understand all Clip parameters, let's create a **picture-in-picture** composition using **two different videos**:\n",
        "- Main video (full screen) â€” video1\n",
        "- Small overlay video (bottom-right corner) â€” video2\n",
        "\n",
        "We'll add both clips to the same track at the same time â€” they'll play simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f23a2a59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "f23a2a59",
        "outputId": "acfcb20b-5099-447c-823a-455f99f797db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/f6893861-828f-4ea7-8b41-6e92ee0645da.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7358c1b80>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/f6893861-828f-4ea7-8b41-6e92ee0645da.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Main video (full screen) - video1\n",
        "main_clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    fit=Fit.crop\n",
        ")\n",
        "\n",
        "# Small overlay video (bottom-right, greyscale) - video2\n",
        "overlay_clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.top_left,\n",
        "    scale=0.7,\n",
        "    filter=Filter.greyscale,\n",
        "    offset=Offset(x=-0.02, y=-0.02),  # Small margin from edge\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, main_clip)\n",
        "track.add_clip(0, overlay_clip)  # Same start time = simultaneous playback\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2306f94",
      "metadata": {
        "id": "c2306f94"
      },
      "source": [
        "**Result**: A classic picture-in-picture layout with **two different videos**!\n",
        "\n",
        "- video1 (main) fills the screen\n",
        "- video2 (overlay, 70% size, greyscale) sits in the top-left corner\n",
        "- Both play simultaneously\n",
        "\n",
        "Notice how `track.add_clip(0, ...)` for both clips makes them play at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0f16a9",
      "metadata": {
        "id": "4a0f16a9"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 20: Split-Screen Effect\n",
        "\n",
        "Let's create a split-screen composition using **two different videos side-by-side**.\n",
        "\n",
        "Strategy:\n",
        "- video1 on the left\n",
        "- video2 on the right (with greyscale filter)\n",
        "- Scale both to 50% width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4a91dd2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "4a91dd2e",
        "outputId": "f5c4e3ac-0208-44a9-f3f6-f5ea622fd099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/1c80a3f3-8077-42af-9379-0567c9f69564.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef7358c2b70>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/1c80a3f3-8077-42af-9379-0567c9f69564.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# Left side clip - video1\n",
        "left_clip = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=10,\n",
        "    position=Position.left,\n",
        "    scale=1,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "# Right side clip - video2 (with greyscale filter)\n",
        "right_clip = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=10,\n",
        "    position=Position.right,\n",
        "    scale=1,\n",
        "    filter=Filter.greyscale,\n",
        "    fit=None\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, left_clip)\n",
        "track.add_clip(0, right_clip)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da51db3",
      "metadata": {
        "id": "4da51db3"
      },
      "source": [
        "**Result**: A split-screen effect with **two different videos**:\n",
        "- Left side: video1 (color)\n",
        "- Right side: video2 (greyscale)\n",
        "\n",
        "This demonstrates how **Clip controls enable spatial composition** â€” placing multiple clips in precise positions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f735e7d0",
      "metadata": {
        "id": "f735e7d0"
      },
      "source": [
        "---\n",
        "\n",
        "## ðŸ“¦ Step 21: Sequential Clips with Transitions\n",
        "\n",
        "Clips don't have to overlap. Let's create **three different videos playing one after another**, each with fade transitions and different effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b29879c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "b29879c2",
        "outputId": "c1ede3da-d9a0-455e-d113-615b7a1a4002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream URL: https://play.videodb.io/v1/b094c356-eddd-40db-8d50-c139c6d6c099.m3u8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7ef73589b2c0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://console.videodb.io/player?url=https://play.videodb.io/v1/b094c356-eddd-40db-8d50-c139c6d6c099.m3u8\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "timeline = Timeline(conn)\n",
        "timeline.background = \"#2B2B2B\"\n",
        "\n",
        "# First clip (0-6 seconds)\n",
        "clip1 = Clip(\n",
        "    asset=VideoAsset(id=video1.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "# Second clip (6-12 seconds)\n",
        "clip2 = Clip(\n",
        "    asset=VideoAsset(id=video2.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "# Third clip (12-18 seconds)\n",
        "clip3 = Clip(\n",
        "    asset=VideoAsset(id=video3.id),\n",
        "    duration=6,\n",
        "    transition=Transition(in_=\"fade\", out=\"fade\", duration=1)\n",
        ")\n",
        "\n",
        "track = Track()\n",
        "track.add_clip(0, clip1)\n",
        "track.add_clip(6, clip2)\n",
        "track.add_clip(12, clip3)\n",
        "timeline.add_track(track)\n",
        "\n",
        "stream_url = timeline.generate_stream()\n",
        "print(f\"Stream URL: {stream_url}\")\n",
        "play_stream(stream_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc0c38c",
      "metadata": {
        "id": "1fc0c38c"
      },
      "source": [
        "**ðŸŽ¬ Result**: A continuous 18-second video with smooth transitions between three different scenes, each with its own unique styling (first clip normal, second clip greyscale, third clip scaled down)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9229622c",
      "metadata": {
        "id": "9229622c"
      },
      "source": [
        "**Timeline structure**:\n",
        "- 0-6s: Normal video with fade in/out\n",
        "- 6-12s: Greyscale video with fade in/out\n",
        "- 12-18s: Smaller video (70% size) with fade in/out\n",
        "\n",
        "Each clip has different visual properties, demonstrating how **Clip acts as the control layer** for every piece of content on your timeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e184baa8",
      "metadata": {
        "id": "e184baa8"
      },
      "source": [
        "---\n",
        "\n",
        "# Wrap-Up\n",
        "\n",
        "## What You've Learned\n",
        "\n",
        "Congratulations! You now understand the **Clip** object â€” the most important control layer in VideoDB Editor.\n",
        "\n",
        "**Key concepts covered**:\n",
        "\n",
        "1. **Asset vs Clip**: Assets provide content; Clips control presentation\n",
        "2. **Position**: 9 preset zones (`Position.center`, `Position.topRight`, etc.)\n",
        "3. **Offset**: Fine-tuning position with relative x/y values\n",
        "4. **Scale**: Size multiplier (0.0 to 10.0)\n",
        "5. **Opacity**: Transparency control (0.0 to 1.0)\n",
        "6. **Fit modes**: How assets scale to viewport (`crop`, `contain`, `cover`, `none`)\n",
        "7. **Filters**: Color treatments (`greyscale`, `blur`, `contrast`, etc.)\n",
        "8. **Transitions**: Fade in/out effects\n",
        "9. **Double Start**: `VideoAsset(start=...)` vs `track.add_clip(start=...)`\n",
        "10. **Composition**: Combining multiple clips with different effects\n",
        "\n",
        "\n",
        "---\n",
        "Every parameter works together to give you complete control over how content appears.\n",
        "\n",
        "## Experiment Further\n",
        "\n",
        "Try these ideas to deepen your understanding:\n",
        "\n",
        "1. **Create a 4-way split**: Position four clips in each corner\n",
        "2. **Animate with opacity**: Create clips with varying opacity levels\n",
        "3. **Filter experiments**: Try all filter types to see their effects\n",
        "4. **Complex timing**: Use `VideoAsset(start=...)` and `track.add_clip(start=...)` together\n",
        "5. **Layer effects**: Combine multiple filters, scales, and positions\n",
        "\n",
        "The Clip object is your primary tool for video composition in Editor â€” master it, and you can build any visual effect you imagine!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}