{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPQoyuq5t4L_"
   },
   "source": [
    "# 2025 in Frames\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/editor/creative/2025_in_Frames.ipynb)\n",
    "\n",
    "### A Personalized Video Year in Review\n",
    "\n",
    "Turn your video analytics into a shareable 33-second recap video.\n",
    "\n",
    "This notebook creates a cinematic journey through your 2025 video stats:\n",
    "- Total minutes uploaded with growth metrics\n",
    "- Search activity visualization\n",
    "- Clips generated via automation\n",
    "- Scenes and frames analyzed\n",
    "- All set to music with dynamic video grids and text overlays\n",
    "\n",
    "All powered by **VideoDB's Editor SDK** - turning data into a visual story through code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Setup\n",
    "\n",
    "First, let's install the VideoDB SDK that powers all our video editing magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vy7lPR1_30Dc",
    "outputId": "6d1faea9-1d9a-407c-cc57-730d7a2ff0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for videodb (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "%pip -q install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "We'll import all the necessary modules from VideoDB for video handling, editing, and playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2eUVoJ1P3aNY"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import videodb\n",
    "import os\n",
    "\n",
    "from videodb import MediaType, play_stream\n",
    "from getpass import getpass\n",
    "from videodb import play_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to VideoDB\n",
    "\n",
    "Enter your API key to authenticate and access your video collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLyJJtliFwln",
    "outputId": "e6bd896b-cacf-47b9-9dbb-c91f1a217b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‘ Enter your VideoDB API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "âœ… Connected to VideoDB!\n"
     ]
    }
   ],
   "source": [
    "# Connect to VideoDB\n",
    "api_key = getpass(\"ðŸ”‘ Enter your VideoDB API Key: \")\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = api_key\n",
    "\n",
    "conn = videodb.connect()\n",
    "coll = conn.get_collection()\n",
    "\n",
    "print(\"âœ… Connected to VideoDB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Step 1: Calculate Your Metrics\n",
    "\n",
    "Time to crunch the numbers! We'll fetch all your uploaded videos and calculate key metrics like total minutes indexed, clips generated, and scenes analyzed.\n",
    "\n",
    "These metrics will be transformed into the visual story throughout the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXosQGelkezj"
   },
   "outputs": [],
   "source": [
    "videos = coll.get_videos()\n",
    "\n",
    "TOTAL_SECONDS = 0\n",
    "for v in videos:\n",
    "  TOTAL_SECONDS += v.length\n",
    "\n",
    "# Core metrics\n",
    "TOTAL_MINUTES = round(TOTAL_SECONDS / 60, 1)\n",
    "# Below matrix can be tracked from usage history of user.\n",
    "TOTAL_SEARCHES = 2573\n",
    "CLIPS_GENERATED = 574\n",
    "SCENES_ANALYZED = 248\n",
    "FRAMES_ANALYZED = 3200\n",
    "\n",
    "# Previous year comparison (for growth %)\n",
    "PREV_YEAR_MINUTES = 6400\n",
    "\n",
    "# Upload time conversions\n",
    "TOTAL_HOURS = round(TOTAL_MINUTES / 60, 1)\n",
    "TOTAL_DAYS = round(TOTAL_HOURS / 24, 1)\n",
    "\n",
    "# Growth percentages\n",
    "MINUTES_GROWTH = round(((TOTAL_MINUTES - PREV_YEAR_MINUTES) / PREV_YEAR_MINUTES) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽµ Step 2: Upload Background Music\n",
    "\n",
    "Every great video needs a soundtrack! Upload your background music track that will play throughout the entire recap video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mELcVCJ8CxT"
   },
   "outputs": [],
   "source": [
    "# upload audio\n",
    "\n",
    "audio = coll.upload(\"https://youtu.be/vIEi8AoP_Fw?si=AUVUt6Komqtt7rWI\", media_type=\"audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¬ Step 3: Initialize Timeline and Tracks\n",
    "\n",
    "Now we set up the foundation of our video:\n",
    "- Create the main **Timeline** with resolution and background color\n",
    "- Set up separate **Tracks** for text overlays and video clips\n",
    "- Prepare to layer our content like a professional video editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc1tz7btmqia"
   },
   "outputs": [],
   "source": [
    "from videodb.editor import (\n",
    "    Timeline,\n",
    "    Track,\n",
    "    Clip,\n",
    "    VideoAsset,\n",
    "    AudioAsset,\n",
    "    TextAsset,\n",
    "    Offset,\n",
    "    Transition,\n",
    "    Font,\n",
    "    Filter,\n",
    ")\n",
    "\n",
    "videos = videos[20:40]\n",
    "\n",
    "timeline = Timeline(conn)\n",
    "timeline.background = \"#E85E00\"\n",
    "track = Track()\n",
    "video_track = Track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¼ Step 4: Add Background Music Track\n",
    "\n",
    "Add the background music that will play throughout the video, creating the emotional foundation for our visual story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIP3NRkEnCrM"
   },
   "outputs": [],
   "source": [
    "# Add backgound music\n",
    "\n",
    "b_music = Clip(\n",
    "    asset=AudioAsset(id=audio.id, start=0, volume=1),\n",
    "    duration=28,\n",
    ")\n",
    "track.add_clip(4, b_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ¨ Step 5: Create the Intro Section\n",
    "\n",
    "**Duration:** 0-5 seconds\n",
    "\n",
    "The opening moment that hooks viewers! We create:\n",
    "- A bold intro text: *\"2025 was a blur. Let's index it.\"*\n",
    "- 60 video clips arranged in a cascading grid with varying scales and positions\n",
    "- Creates a dynamic, eye-catching mosaic effect that builds anticipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BC57OCJmviO"
   },
   "outputs": [],
   "source": [
    "# intro text\n",
    "\n",
    "intro_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=\"2025 was a blur. Let's index it.\",\n",
    "        font=Font(size=60, family=\"Roboto Bold\"),\n",
    "    ),\n",
    "    duration=5,\n",
    "    transition=Transition(in_=\"fade\"),\n",
    ")\n",
    "track.add_clip(1, intro_text)\n",
    "\n",
    "# Create 20 video clips with 1 second duration each and different scales\n",
    "# Scales range from 0.5 to 0.95\n",
    "for i in range(60):\n",
    "    scale_value = 0.5 + (i * 0.025)  # Scale: 0.5, 0.525, 0.55, ... 0.975\n",
    "    start_time = random.randint(0, 4)\n",
    "    volume = 0.5\n",
    "    if start_time == 3:\n",
    "        volume = 0.3\n",
    "    elif start_time == 4:\n",
    "        volume = 0.3\n",
    "\n",
    "    # Pick a random video for each clip\n",
    "    video = random.choice(videos)\n",
    "\n",
    "    video_clip = Clip(\n",
    "        asset=VideoAsset(\n",
    "            id=video.id,\n",
    "            start=random.randint(\n",
    "                10, int(video.length - 10)\n",
    "            ),  # Start from different positions in the source video\n",
    "            volume=volume,\n",
    "        ),\n",
    "        duration=1,  # 1 second each\n",
    "        scale=scale_value,\n",
    "        fit=None,\n",
    "        offset=Offset(x=random.uniform(-0.5, 0.5), y=random.uniform(-0.5, 0.5)),\n",
    "    )\n",
    "\n",
    "    # Add each clip at sequential 1-second intervals\n",
    "    video_track.add_clip(start=start_time, clip=video_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ˆ Step 6: Section 1 - Upload Metrics\n",
    "\n",
    "**Duration:** 6-13 seconds\n",
    "\n",
    "Showcase your upload statistics with a dramatic **zoom-out effect**:\n",
    "- Display total minutes, hours, and days of content uploaded\n",
    "- Show year-over-year growth percentage\n",
    "- 20 video clips that start large and scale down, creating a cinematic reveal\n",
    "- Greyscale filter adds a sophisticated, professional look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsgMrqoNnY7-"
   },
   "outputs": [],
   "source": [
    "# section 1st\n",
    "\n",
    "section1_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=f\"You uploaded {TOTAL_MINUTES:,} minutes\\nof video content.\\n\\nThat's {TOTAL_HOURS} hours.\\nOr {TOTAL_DAYS} full days of footage.\\n\\nâ†‘ {MINUTES_GROWTH}% from 2024\",\n",
    "        font=Font(size=48, family=\"default\"),\n",
    "    ),\n",
    "    duration=7,\n",
    ")\n",
    "track.add_clip(6, section1_text)\n",
    "\n",
    "# Zoom out effect for section 1 using video assets\n",
    "# Videos start large and scale down (zoom out effect)\n",
    "for i in range(20):\n",
    "    scale_value = 0.5 + (i * 0.0263)  # Scale: 0.5, 0.526, ... 1.0 (zoom out effect)\n",
    "    start_time = 6 + (i * 0.175)  # Spread across section 1 duration (7 seconds)\n",
    "\n",
    "    # Pick a random video for each clip\n",
    "    video = random.choice(videos)\n",
    "\n",
    "    # Safe video start time\n",
    "    video_start = random.randint(10, max(11, int(video.length - 10)))\n",
    "\n",
    "    video_clip = Clip(\n",
    "        asset=VideoAsset(\n",
    "            id=video.id,\n",
    "            start=video_start,\n",
    "            volume=0.15,\n",
    "        ),\n",
    "        duration=1,\n",
    "        scale=scale_value,\n",
    "        fit=\"crop\",\n",
    "        filter=Filter.greyscale,\n",
    "    )\n",
    "\n",
    "    video_track.add_clip(start=start_time, clip=video_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ” Step 7: Section 2 - Search Analytics\n",
    "\n",
    "**Duration:** 13-19 seconds\n",
    "\n",
    "Visualize your search activity with a **horizontal scanning effect**:\n",
    "- Display the total number of questions asked\n",
    "- 3 rows of video clips moving horizontally at different speeds\n",
    "- Creates a dynamic \"data stream\" visual that represents video intelligence in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g79cCvi0nkzR"
   },
   "outputs": [],
   "source": [
    "# secction 2nd\n",
    "\n",
    "section2_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=f\"{TOTAL_SEARCHES:,} questions asked.\\n\\nYour videos aren't just storedâ€”\\nthey're understood.\",\n",
    "        font=Font(size=58, family=\"default\"),\n",
    "    ),\n",
    "    duration=6,\n",
    ")\n",
    "track.add_clip(13, section2_text)\n",
    "\n",
    "rows = [\n",
    "    {\"y\": -0.5, \"num_clips\": 20, \"duration\": 0.25, \"scale\": 0.35},  # Top - fastest\n",
    "    {\"y\": 0, \"num_clips\": 15, \"duration\": 0.33, \"scale\": 0.45},  # Middle - medium\n",
    "    {\"y\": 0.5, \"num_clips\": 12, \"duration\": 0.42, \"scale\": 0.35},  # Bottom - slowest\n",
    "]\n",
    "\n",
    "clip_idx = 0\n",
    "for row in rows:\n",
    "    for i in range(row[\"num_clips\"]):\n",
    "        x_pos = -0.9 + (i * 0.1)  # Move left to right\n",
    "        video = videos[clip_idx % len(videos)]\n",
    "\n",
    "        # Safe video start time - make sure it doesn't exceed video length\n",
    "        video_start = 30 + (clip_idx % 10)  # Cycle through 30-40 seconds\n",
    "        if video_start > video.length - 10:\n",
    "            video_start = 15  # Fallback to safe position\n",
    "\n",
    "        video_clip = Clip(\n",
    "            asset=VideoAsset(\n",
    "                id=video.id,\n",
    "                start=video_start,\n",
    "                volume=0.15,\n",
    "            ),\n",
    "            duration=row[\"duration\"],\n",
    "            scale=row[\"scale\"],\n",
    "            fit=\"crop\",\n",
    "            offset=Offset(x=x_pos, y=row[\"y\"]),\n",
    "        )\n",
    "        video_track.add_clip(start=12 + (i * row[\"duration\"]), clip=video_clip)\n",
    "        clip_idx += 1\n",
    "\n",
    "\n",
    "section3_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=f\"{CLIPS_GENERATED:,} clips\\ngenerated via code.\\n\\nAutomation at its finest.\",\n",
    "        font=Font(size=62, family=\"default\"),\n",
    "    ),\n",
    "    duration=6,\n",
    ")\n",
    "track.add_clip(19, section3_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ¤– Step 8: Section 3 - Automation Stats\n",
    "\n",
    "**Duration:** 19-25 seconds\n",
    "\n",
    "Highlight the power of automation with a **cycling background effect**:\n",
    "- Showcase total clips generated via code\n",
    "- Large, cycling background clips create a sense of scale and automation\n",
    "- Emphasizes the \"code-first\" approach to video creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKsSRhpUnvAc"
   },
   "outputs": [],
   "source": [
    "# section 3rd\n",
    "\n",
    "section3_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=f\"{CLIPS_GENERATED:,} clips\\ngenerated via code.\\n\\nAutomation at its finest.\",\n",
    "        font=Font(size=62, family=\"default\"),\n",
    "    ),\n",
    "    duration=6,\n",
    ")\n",
    "track.add_clip(19, section3_text)\n",
    "\n",
    "# Add continuous cycling large background clip throughout section 3\n",
    "for i in range(3):\n",
    "    video = videos[(i + 5) % len(videos)]\n",
    "    video_start = 20 + (i * 15)\n",
    "    if video_start > video.length - 10:\n",
    "        video_start = 10\n",
    "\n",
    "    bg_clip = Clip(\n",
    "        asset=VideoAsset(\n",
    "            id=video.id,\n",
    "            start=video_start,\n",
    "            volume=0.05,\n",
    "        ),\n",
    "        duration=2,\n",
    "        scale=1.2,\n",
    "        fit=\"crop\",\n",
    "        filter=Filter.greyscale,\n",
    "        opacity=0.2,\n",
    "        z_index=0,\n",
    "    )\n",
    "    video_track.add_clip(start=19 + (i * 2), clip=bg_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§  Step 9: Section 4 - Intelligence Metrics\n",
    "\n",
    "**Duration:** 25-31 seconds\n",
    "\n",
    "Display video intelligence capabilities with a **scanning grid animation**:\n",
    "- Show scenes and frames analyzed\n",
    "- 3x3 grid of video clips appears sequentially with scanning effect\n",
    "- Two columns of cascading clips create a \"data processing\" visual\n",
    "- Alternating contrast and boost filters add visual rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDh2as36n-ZW"
   },
   "outputs": [],
   "source": [
    "# section 4th\n",
    "\n",
    "section4_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=f\"{SCENES_ANALYZED:,} scenes analyzed\\n{FRAMES_ANALYZED:,} Frames Analyzed\\n\\nPure video intelligence.\\nPowered by you.\",\n",
    "        font=Font(size=52, color=\"#FFFFFF\", family=\"Arial Bold\"),\n",
    "    ),\n",
    "    duration=5,\n",
    ")\n",
    "track.add_clip(25, section4_text)\n",
    "\n",
    "# Section 4 animation: Improved grid with continuous background\n",
    "# Create a 3x3 grid of video clips that appear sequentially\n",
    "grid_positions = [\n",
    "    (-0.4, -0.4),\n",
    "    (0, -0.4),\n",
    "    (0.4, -0.4),  # Top row\n",
    "    (-0.4, 0),\n",
    "    (0, 0),\n",
    "    (0.4, 0),  # Middle row\n",
    "    (-0.4, 0.4),\n",
    "    (0, 0.4),\n",
    "    (0.4, 0.4),  # Bottom row\n",
    "]\n",
    "\n",
    "# Main grid appears with scanning effect\n",
    "for idx, (x_pos, y_pos) in enumerate(grid_positions):\n",
    "    video = videos[idx % len(videos)]\n",
    "\n",
    "    # Safe video start\n",
    "    video_start = 50 + (idx % 10)\n",
    "    if video_start > video.length - 10:\n",
    "        video_start = 20\n",
    "\n",
    "    # Create scanning effect with transitions and filters\n",
    "    video_clip = Clip(\n",
    "        asset=VideoAsset(\n",
    "            id=video.id,\n",
    "            start=video_start,\n",
    "            volume=0.1,\n",
    "        ),\n",
    "        duration=0.6,\n",
    "        scale=0.28,\n",
    "        fit=\"crop\",\n",
    "        offset=Offset(x=x_pos, y=y_pos),\n",
    "        transition=Transition(in_=\"fade\", duration=0.15),\n",
    "        filter=Filter.contrast if idx % 2 == 0 else Filter.boost,\n",
    "        opacity=0.9,\n",
    "    )\n",
    "\n",
    "    # Stagger the appearance for scanning effect\n",
    "    video_track.add_clip(start=24.5 + (idx * 0.08), clip=video_clip)\n",
    "\n",
    "num_columns = 2\n",
    "clips_per_column = 8\n",
    "for col in range(num_columns):\n",
    "    x_pos = -0.3 + (col * 0.6)  # Two columns centered in viewport\n",
    "\n",
    "    for row in range(clips_per_column):\n",
    "        y_pos = -0.7 + (row * 0.23)  # Top to bottom\n",
    "        clip_idx = col * clips_per_column + row\n",
    "\n",
    "        video = videos[clip_idx % len(videos)]\n",
    "\n",
    "        # Safe video start\n",
    "        video_start = 40 + (clip_idx % 8)\n",
    "        if video_start > video.length - 10:\n",
    "            video_start = 25\n",
    "\n",
    "        video_clip = Clip(\n",
    "            asset=VideoAsset(\n",
    "                id=video.id,\n",
    "                start=video_start,\n",
    "                volume=0.15,\n",
    "            ),\n",
    "            duration=0.3,\n",
    "            scale=0.3,\n",
    "            fit=\"crop\",\n",
    "            offset=Offset(x=x_pos, y=y_pos),\n",
    "        )\n",
    "        # Stagger between columns for cascading effect\n",
    "        video_track.add_clip(start=25.7 + (row * 0.3) + (col * 0.1), clip=video_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Step 10: Create the Outro\n",
    "\n",
    "**Duration:** 31-33 seconds\n",
    "\n",
    "End with a forward-looking call to action: *\"Ready for 2026? Build it.\"*\n",
    "\n",
    "A simple, powerful message that leaves viewers inspired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60Q_gVS-oPvq"
   },
   "outputs": [],
   "source": [
    "# outro text\n",
    "\n",
    "outro_text = Clip(\n",
    "    asset=TextAsset(\n",
    "        text=\"Ready for 2026? Build it.\", font=Font(size=60, family=\"Roboto Bold\")\n",
    "    ),\n",
    "    duration=2,\n",
    "    # transition=Transition(in_=\"fade\"),\n",
    ")\n",
    "track.add_clip(31, outro_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¥ Step 11: Compile and Generate the Final Video\n",
    "\n",
    "Time to bring it all together! We'll:\n",
    "1. Add all tracks to the timeline (video track first, then text track for proper layering)\n",
    "2. Generate the final stream URL\n",
    "3. Preview the complete 33-second journey through your 2025 achievements\n",
    "\n",
    "Watch as your data transforms into a cinematic experience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "OGkdcxs_odpf",
    "outputId": "621214da-c673-45ce-82b6-6be0db27423e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://d1zudc7ewmc6ey.cloudfront.net/v1/a0f7b1cd-26b1-4c1b-b2d8-deaef0be5524.m3u8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"https://console.videodb.io/player?url=https://d1zudc7ewmc6ey.cloudfront.net/v1/a0f7b1cd-26b1-4c1b-b2d8-deaef0be5524.m3u8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ad3ac226840>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline.add_track(video_track)\n",
    "timeline.add_track(track)\n",
    "\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "print(stream_url)\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## That's a Wrap!\n",
    "\n",
    "We just turned raw analytics into a 33-second cinematic journey - all with code!\n",
    "\n",
    "### What we built:\n",
    "- **Multi-layered timeline** - Separate tracks for audio, visuals, and text\n",
    "- **Procedural animation** - 100+ video clips positioned through code\n",
    "- **Dynamic effects** - Zoom transitions, scanning grids, cascading animations\n",
    "- **Data storytelling** - Metrics transformed into engaging visuals\n",
    "\n",
    "### The Magic of VideoDB Editor SDK:\n",
    "- No manual editing - everything defined in Python\n",
    "- Precise control over positioning, timing, and transitions\n",
    "- Reusable patterns for different data sets\n",
    "- Generate multiple versions by changing input metrics\n",
    "\n",
    "**Want your own recap?** Just update the metrics in Step 1 and run the cells!\n",
    "\n",
    "---\n",
    "\n",
    "*Made with VideoDB Editor SDK*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
