{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä Eleven Labs x VideoDB: Adding AI Generated voiceovers to silent footage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/Elevenlabs_Voiceover_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Voiceovers are the secret sauce that turns silent footage into captivating stories. They add depth, emotion, and excitement, elevating the viewing experience to new heights. With [VideoDB](https://videodb.io)'s cutting-edge technology, creating dynamic voiceovers for your videos is easier and more thrilling than ever before.\n",
    "\n",
    "Creating AI content and merging outputs from different tools can be tough and time-consuming. Doing it manually is even harder! What if you could do it all- in just a few lines of code? \n",
    "\n",
    "[VideoDB](https://videodb.io)'s cool tech helps you generate intelligent AI content and combine outputs from various tools quickly and automatically. No more long and tedious processes. Just simple, efficient, and awesome results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let‚Äôs try adding an automatically generated voiceover to [this silent footage](https://youtu.be/RcRjY5kzia8) in the style and voice of Sir David Attenborough. We shall do this using the powerful tech provided by `Open AI`, `ElevenLabs` and `VideoDB`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/video-db/videodb-cookbook/main/images/Elevenlabs_Voiceover_1/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶  Installing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë API Keys\n",
    "Before proceeding, ensure access to [VideoDB](https://videodb.io), [OpenAI](https://openai.com), and [ElevenLabs](https://elevenlabs.io) API key. If not, sign up for API access on the respective platforms.\n",
    "\n",
    "> Get your API key from [VideoDB Console](https://console.videodb.io). ( Free for first 50 uploads, **No credit card required** ) üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import videodb\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt user for API key securely\n",
    "api_key = getpass(\"Please enter your VideoDB API Key: \")\n",
    "os.environ[\"VIDEO_DB_API_KEY\"] = api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"ELEVEN_LABS_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéôÔ∏è  ElevenLab's Voice ID  \n",
    "You will also need ElevenLab's VoiceID of a Voice that you want to use.\n",
    "\n",
    "For this demo, we will be using [David Attenborough's Voice](https://elevenlabs.io/app/voice-lab/share/2ee40b08feb5b536baa392b1efc25f1cbbf432099b40982407990f4aa0dfe8a7/iJVpwDOsPQAptMKoj1ea). ElevenLabs has a large variety of voices to choose from (browse them [here](https://elevenlabs.io/voice-library)). Once finalized, copy the Voice ID from ElevenLabs and link it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiceover_artist_id = \"VOICEOVER_ARTIST_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üåê Step 1: Connect to VideoDB\n",
    "Connect to VideoDB using your API key to establish a session for uploading and manipulating video files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# Connect to VideoDB using your API key\n",
    "conn = connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé• Step 2: Upload Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a video by URL (replace the url with your video)\n",
    "video = conn.upload(url='https://youtu.be/RcRjY5kzia8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Step 3: Analyze Scenes and Generate Scene Descriptions\n",
    "\n",
    "Start by analyzing the scenes within your Video using VideoDB's scene indexing capabilities. This will provide context for generating the script prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.index_scenes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the description of first scene of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 9.033333333333333\n",
      "The image displays an abstract array of blue shades forming a textured pattern resembling overlapping petals or scales. The hues range from deep cobalt to turquoise, intimating a fluid or organic essence reminiscent of natural elements like water or foliage. The amalgamation of shapes and colors creates a vibrant mosaic, without any discernible figures or familiar forms. It conveys a sense of calmness and depth, akin to peering into a cerulean sea or a cluster of exotic flowers. This image could be interpreted as a close-up of scales, artistic rendering, or a digitally altered photograph, with its focus on the interplay of color and form.\n"
     ]
    }
   ],
   "source": [
    "scenes = video.get_scenes()\n",
    "print(f\"{scenes[0]['start']} - {scenes[0]['end']}\")\n",
    "print(scenes[0][\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Generate Voiceover Script with LLM\n",
    "Combine scene descriptions with the script prompt, instructing LLM to create a voiceover script in David Attenborough's style.\n",
    "\n",
    "This script prompt can be refined and tweaked to generate the most suitable output. Check out [these examples](https://www.youtube.com/playlist?list=PLhxAMFLSSK03rsPTjRv1LbAXHQpNN6BS0) to explore more use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "script_prompt = \"Here's the data from a scene index for a video about the underwater world. Study this and then generate a synced script based on the description below. Make sure the script is in the language, voice and style of Sir David Attenborough\"\n",
    "\n",
    "full_prompt = script_prompt + \"\\n\\n\"\n",
    "for scene in scenes:\n",
    "  full_prompt += f\"- {scene}\\n\"\n",
    "\n",
    "openai_res = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    ")\n",
    "voiceover_script = openai_res.choices[0].message.content\n",
    "\n",
    "# If you have ElevenLab's paid plan remove this\n",
    "voiceover_script = voiceover_script[:2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé§ Step 5: Generate Voiceover Audio with ElevenLabs\n",
    "Utilize the generated script to synthesize AI-generated voiceover narration in David Attenborough's voice using ElevenLabs API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Call ElevenLabs API to generate voiceover\n",
    "url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voiceover_artist_id}\"\n",
    "headers = {\n",
    "    \"xi-api-key\": os.environ.get(\"ELEVEN_LABS_API_KEY\"),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model_id\": \"eleven_monolingual_v1\",\n",
    "    \"text\": voiceover_script,\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.5,\n",
    "        \"similarity_boost\": 0.5\n",
    "    }\n",
    "}\n",
    "elevenlabs_res = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "# Save the audio file\n",
    "audio_file = \"audio.mp3\"\n",
    "CHUNK_SIZE = 1024\n",
    "with open(audio_file, 'wb') as f:\n",
    "    for chunk in elevenlabs_res.iter_content(chunk_size=CHUNK_SIZE):\n",
    "        if chunk:\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé¨ Step 6: Add Voiceover to Video with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the voiceover generated above, let's upload the audio file (voiceover) to VideoDB first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = conn.upload(file_path=audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the AI-generated voiceover to the original footage using VideoDB's [timeline feature](https://docs.videodb.io/version-0-0-3-timeline-and-assets-44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset, AudioAsset\n",
    "\n",
    "# Create a timeline object\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "# Add the video asset to the timeline for playback\n",
    "video_asset = VideoAsset(asset_id=video.id)\n",
    "timeline.add_inline(asset=video_asset)\n",
    "\n",
    "# Add the audio asset to the timeline for playback\n",
    "audio_asset = AudioAsset(asset_id=audio.id)\n",
    "timeline.add_overlay(start=0, asset=audio_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ Step 7: Review and Share\n",
    "Preview the video with the integrated voiceover to ensure it functions correctly.   \n",
    "Once satisfied, generate a stream of the video and share the link for others to view and enjoy this wholesome creation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import play_stream\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéâ Conclusion:\n",
    "Congratulations! You have successfully automated the process of creating custom and personalized voiceovers based on a simple prompt and raw video footage using VideoDB, OpenAI, and ElevenLabs.\n",
    "\n",
    "By leveraging advanced AI technologies, you can enhance the storytelling and immersive experience of your video content. Experiment with different prompts and scene analysis techniques to further improve the quality and accuracy of the voiceovers. Enjoy creating captivating narratives with AI-powered voiceovers using VideoDB! \n",
    "\n",
    "For more such explorations, refer to the [documentation of VideoDB](https://docs.videodb.io/) and join the VideoDB community on [GitHub](https://github.com/video-db) or [Discord](https://discord.com/invite/py9P639jGz) for support and collaboration.\n",
    "\n",
    "We're excited to see your creations, so we welcome you to share your creations via [Discord](https://discord.com/invite/py9P639jGz), [LinkedIn](https://www.linkedin.com/company/videodb) or [Twitter](https://twitter.com/videodb_io)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
