{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/video-db/videodb-cookbook/blob/main/examples/creating_clips_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "In this tutorial, we are going to use VideoDB to create clips of a your favorite character.  No need for fancy editing software or waiting around â€“ you get to see your video right away. âš¡ï¸\n",
    "\n",
    "Want to know more about VideoDB? Read on [here](https://videodb.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "---  \n",
    "\n",
    "For our demonstration, \n",
    "\n",
    "1. We've selected a 15-minute clip from HBO's \"Silicon Valley\" show. You can view the clip here: [Silicon Valley Clip on YouTube](https://www.youtube.com/watch?v=NNAgJ5p4CIY)\n",
    "2. We've done some analysis on this video and identified specific times when certain characters appear. This was achieved using AWS Rekognition API. If you're curious about the full process, including how to index faces and pinpoint timestamps in videos, check out our [blog](https://docs.videodb.io/unlock-the-power-of-video-analysis-with-videodb-discover-signifi-4) where we walk through the entire process.\n",
    "3. In this blog post, however, we're going to skip the details of video analysis and jump straight to the timestamps.\n",
    "4. We've analyzed the appearances of characters from clip and mapped out where they appear in `persons_data` \n",
    "\n",
    "Next, we'll upload the video to VideoDb and use these timestamps to clip the video. It's as easy as querying a databaseâš¡ï¸!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "---\n",
    "### ðŸ”§ Installing VideoDB in your environment\n",
    "\n",
    "VideoDB is available as [python package ðŸ“¦](https://pypi.org/project/videodb/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”— Setting Up a connection to db\n",
    "\n",
    "To connect to `VideoDB`, simply create a `Connection` object.\n",
    "\n",
    "This can be done by either providing your VideoDB API key directly to the constructor or by setting the `VIDEO_DB_API_KEY` environment variable with your API key.\n",
    "\n",
    "> ðŸ’¡ Your API key is available in the [VideoDB dashboard](https://console.videodb.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect, play_stream\n",
    "conn = connect(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Video Analysis data\n",
    "---\n",
    "\n",
    "The `persons_data` contains timeline  for each character, representing the timestamps of shots when they were present in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_data = [\n",
    "    {\n",
    "        \"name\":\"gilfoyle\",\n",
    "        \"timeline\": [[0, 4], [160, 185], [330, 347], [370, 378], [382, 391], [391, 400]]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"jinyang\",\n",
    "        \"timeline\": [[232, 271], [271, 283], [284, 308], [312, 343], [398, 407]]\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"erlic\",\n",
    "        \"timeline\": [[0, 8], [12, 30], [31, 41], [44, 52], [56, 97], [97, 124], [147, 165], [185, 309], [316, 336], [336, 345], [348, 398], [398, 408]]\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"jared\",\n",
    "        \"timeline\": [[0, 15], [148, 165], [182, 190], [343, 355], [358, 381], [384, 393]]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"dinesh\" ,\n",
    "        \"timeline\": [[0, 4], [160, 189], [343, 354], [374, 383], [392, 402]]\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"richard\" ,\n",
    "        \"timeline\": [[12, 41], [127, 137], [137, 154], [159, 167], [360, 378], [381, 398], [399, 407]]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¬ï¸ Clips \n",
    "---\n",
    "\n",
    "\n",
    "### Generate Clip for each character using VideoDB\n",
    "\n",
    ">The idea behind videodb is straightforward: it functions as a database specifically for videos.   \n",
    ">Similar to how you upload tables or JSON data to a standard database, you can upload your videos to videodb.   \n",
    ">You can also retrieve your videos through queries, swiftly create clips, much like accessing regular data from a database.  \n",
    "\n",
    "For this step,\n",
    "\n",
    "*  We will upload our video to VideoDB using `Connection.upload()`\n",
    "*  Create clips of each character from our analyzed data by passing `timeline` in `Video.generate_stream()`\n",
    "\n",
    "if you pass timeline of your clip in `Video.generate_stream()` , you will get a streaming link of a your clip as a response ( in less than 3s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gilfoyle : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/d25a4c27-dcdd-458c-ad44-627a6e938d1a.m3u8\n",
      "jinyang : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/80040f93-8c16-46f3-a817-74150911caa1.m3u8\n",
      "erlic : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/339a6a0b-3a79-4328-94f2-a8f5467d3204.m3u8\n",
      "jared : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/fb5c27d2-724f-4f07-8e0d-249229adeea8.m3u8\n",
      "dinesh : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/a3cbc831-8600-46f7-b82d-c7ceb1842fcf.m3u8\n",
      "richard : https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/aab6949d-8b52-455f-89cf-02af5614a4f5.m3u8\n"
     ]
    }
   ],
   "source": [
    "video_url_yt = \"https://www.youtube.com/watch?v=NNAgJ5p4CIY\"\n",
    "video = conn.upload(url=video_url_yt)\n",
    "for person in persons_data:\n",
    "  stream_link = video.generate_stream(timeline=person[\"timeline\"])  \n",
    "  person[\"stream_link\"] = stream_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the results in Videodb Player \n",
    "Now, it's time to check out our results.\n",
    "\n",
    "Let's take a look at a clip featuring Erlich Bachman (or, feel free to choose your favorite character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/339a6a0b-3a79-4328-94f2-a8f5467d3204.m3u8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"400\"\n",
       "            src=\"https://console.videodb.io/player?url=https://d27qzqw9ehjjni.cloudfront.net/v3/published/manifests/339a6a0b-3a79-4328-94f2-a8f5467d3204.m3u8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7f504178b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_2_video = persons_data[2][\"stream_link\"]\n",
    "play_stream(person_2_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
